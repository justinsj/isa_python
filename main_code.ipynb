{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Based Structural Analysis\n",
    "### Code created and maintained by Justin David Q. SAN JUAN, <br>email: jdqsj1997@yahoo.com, <br> website: justinsj.weebly.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "#### Dependencies:\n",
    "numpy: for handling data types (mostly handled as numpy arrays)<br>\n",
    "Sequential (from keras.models): for CNN setup<br>\n",
    "random: for pseudo-random shuffling of data<br>\n",
    "cv2: for raw RBG image import and transformation to grayscale<br>\n",
    "time: for measuring time elapsed per function<br>\n",
    "##### Custom Classes:\n",
    "ComponentSegmentation: for proposing regions of interest (RoI's)<br>\n",
    "ExtractionPreprocessing: for trimming, noise removal, and resizing of image<br>\n",
    "ComponentClassifierTraining: for loading the CNN model, training data, and training the model<br>\n",
    "ComponentClassifierPredict: for using the CNN model to predict the class of preprocessed extractions<br>\n",
    "ExtractionLabelling: for labelling ground truth bounding boxes and classes in problem images<br>\n",
    "TestingClass: for testing the accuracy of a CNN model on the problem images<br>\n",
    "<br>\n",
    "gc: for clearing up space after acquiring data from larger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from component_segmentation import ComponentSegmentation\n",
    "from extraction_preprocessing import ExtractionPreprocessing\n",
    "from component_classifier_training import ComponentClassifierTraining\n",
    "from component_classifier_predict import ComponentClassifierPredict\n",
    "from extraction_labelling import ExtractionLabelling\n",
    "from testing_class import TestingClass\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "print('Done Importing...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters\n",
    "#### Selective Search Parameters:\n",
    "scale_input<br>\n",
    "sigma_input<br>\n",
    "min_size_input<br>\n",
    "#### Noise Reduction Parameters:\n",
    "min_shape: for minimum number of black pixels in bounding box<br>\n",
    "min_height: for minimum height of bounding box<br>\n",
    "min_width: for minimum width of bounding box<br>\n",
    "<br>\n",
    "buffer_zone: for expanding bounding box all directions<br>\n",
    "min_area: for minimum area of bounding box<br>\n",
    "min_black: for minimum number of black pixels in bounding box<br>\n",
    "min_black_ratio: for minimum ratio of black pixels to the bounding box area<br>\n",
    "#### Overlap Parameters:\n",
    "overlap_repeats: for number of iterations for merging algorithm to be applied<br>\n",
    "overlap_threshold: threshold of area overlap over union area for merging to be applied<br>\n",
    "#### Removing Unconnected Pieces Parameters:\n",
    "max_piece_percent: maximum percentage of piece to be removed<br>\n",
    "(if percentage is larger, piece will not be removed as it is more likely an important piece)<br>\n",
    "#### Extractions Preprocessing Parameters:\n",
    "img_rows, img_cols: for classifier input shape<br>\n",
    "wanted_w, wanted_h: for black pixels edges resizing boundary shape<br>\n",
    "export_w, export_h: for overall image resizing shape ([export_w-wanted_w]/2 = horizontal buffer on each side)<br>\n",
    "#### CNN Training Parameters:\n",
    "num_classes: number of classes for classifier to predict<br>\n",
    "TRAINING_RATIO_TRAIN: ratio of training samples to total number of samples<br>\n",
    "TRAINING_RATIO_VAL: ratio of validation samples to total number of samples<br>\n",
    "TRAINING_RATIO_TEST: ratio of test samples to total number of samples <br>\n",
    "Note: TRAINING_RATIO_TEST is implicitly calculated as [1-{TRAINING_RATIO_TRAIN + TRAINING_RATIO_VAL}]<br>\n",
    "dropout: dropout value to be used in all layers except last layer of Sketch-A-Net CNN model<br>\n",
    "#### CNN Prediction Parameters:\n",
    "min_percent_match: minimum probability of class prediction for that class to be set as the prediction<br>\n",
    "min_confidence: minimum difference between first-highest % match and second-highest % match<br>\n",
    "(higher difference means less ambiguity between first and second highest match, which means less likelihood of random object)<br>\n",
    "##### The directory is also defined in the PATH variable.\n",
    "##### The name of the CNN model data is defined in the name variable.\n",
    "##### The training data set name for the CNN is defined in the data_set_name variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selective search parameters\n",
    "scale_input=10 #10\n",
    "sigma_input=0 #15\n",
    "min_size_input=5 #5\n",
    "\n",
    "#noise reduction parameters\n",
    "min_shape=40 #min. number of black pixels  \n",
    "min_height=5 #min. height of bounding box\n",
    "min_width=5 #min. width of bounding box\n",
    "\n",
    "buffer_zone=2 #expand bounding box by this amount in all directions  \n",
    "min_area=150 #min. area of bounding box\n",
    "min_black=50 #min. number of black pixels\n",
    "min_black_ratio=0.03 #min ratio of black pixels to the bounding box area\n",
    "\n",
    "#Overlap parameters\n",
    "overlap_repeats = 8 #set to 8\n",
    "overlap_threshold = 0.3 #set to 0.3\n",
    "\n",
    "#Removing unconnected pieces parameters\n",
    "max_piece_percent=0.3  # set to 0.3\n",
    "\n",
    "#Extractions preprocessing paramaters\n",
    "img_rows, img_cols = 100,100\n",
    "wanted_w, wanted_h, export_w, export_h = img_cols, img_rows, img_cols, img_rows\n",
    "\n",
    "#CNN training parameters\n",
    "num_classes = 64\n",
    "TRAINING_RATIO_TRAIN = 0.7\n",
    "TRAINING_RATIO_VAL = 0.15\n",
    "dropout = 0\n",
    "\n",
    "#CNN prediction parameters\n",
    "min_percent_match = 0 # set to 0.7\n",
    "min_confidence = 0 # set to 0.3\n",
    "\n",
    "#Paths and names\n",
    "PATH = '/home/chloong/Desktop/Justin San Juan/Testing Folder/'\n",
    "\n",
    "name = 'Sketch-a-Net_64_classes_100x100_0.0_all_100epochs'\n",
    "\n",
    "data_set_name = 'Training_Samples_64_classes_100x100_all'\n",
    "\n",
    "print('Done setting hyperparamters...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image\n",
    "Image (binary, grayscale, 2D, numpy array) for regions of interest proposals is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time() # Begin time measurement\n",
    "\n",
    "image_index = 0\n",
    "image_set = np.load(PATH+'all_training_images.npy')\n",
    "image = np.copy(image_set[:,:,image_index])\n",
    "image_set = None #clear image_set\n",
    "\n",
    "end = time.time()#record time\n",
    "print('Loading image done... Time Elapsed : '+ str(end-start) + ' seconds...')\n",
    "t1 = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component Segmentation\n",
    "##### Using the ComponentSegmentation class:\n",
    "    1. Selective Search is applied to the image (to generate bounding boxes)\n",
    "    2. A merging algorithm is applied to the selective search bounding boxes (to merge highly overlapping bounding boxes)\n",
    "##### The ComponentSegmentation uses the following data for initialization:\n",
    "    - image: binary (grayscale) 2-D array for region proposal\n",
    "    - name: for unique prints saving\n",
    "    - min_shape, min_height, min_width, buffer_zone, min_area, min_black, min_black_ratio: for noise reduction\n",
    "    - overlap_repeats, overlap_threshold: for merging algorithm\n",
    "##### Then, the RoI proposal is done using the custom search method, which uses the selective search hyper-parameters:\n",
    "    - scale_input\n",
    "    - sigma_input\n",
    "    - min_size_input\n",
    "##### Then, the merging algorithm is applied within the search function, and a merged_set is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time() # Begin time measurement\n",
    "\n",
    "#Create object ComponentSegmentation, which will use the search function to perform segmentation and merging.\n",
    "segmentation_obj = ComponentSegmentation(image, name, min_shape, min_height, min_width, buffer_zone, min_area, min_black, min_black_ratio, overlap_repeats, overlap_threshold)\n",
    "segmentation_obj.search(scale_input, sigma_input, min_size_input) # run search (segmentation code)\n",
    "merged_set = segmentation_obj.merged_set\n",
    "\n",
    "end = time.time()#record time\n",
    "print('ComponentSegmentation done... Time Elapsed : '+ str(end-start) + ' seconds...')\n",
    "t2 = end-start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtractionPreprocessing\n",
    "#### Merged set from ComponentSegmentation is passed to ExtractionPreprocessing and the following is applied:\n",
    "    1. Trim: extra space around the farthest black pixels are removed\n",
    "    2. Remove Unconnected Parts: extra pixels (from other components) captured by the bounding box are removed\n",
    "    3. Trim: trimming again as empty spaces may be released\n",
    "    4. Resize: extraction is resized to the prescribed 100x100 dimension using max pooling for downsampling to preserve data\n",
    "ext_images = extraction images: list of 100x100 binary (grayscale) 2-D arrays<br>\n",
    "ext_data = extraction data: list of x, y, w, h data of extractions bounding boxes<br> \n",
    "where:<br>\n",
    "    - x, y: top-left corner coordinates of bounding box\n",
    "    - w, h: width and height of bounding box respectively\n",
    "#### The preprocess_extractions function is called and the extraction images and extraction data are acquired.\n",
    "#### The plot_bounding_boxes_with_names function is then used to display the bounding boxes on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transport data into ExtractionPreprocessing class, which will trim, remove unconnected parts, then trim, and resize\n",
    "extraction_obj = ExtractionPreprocessing(image, name, merged_set)\n",
    "\n",
    "# Get 4 lists from preprocess_extractions function\n",
    "ext_images, ext_data = extraction_obj.preprocess_extractions(wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "extraction_obj.plot_bounding_boxes_with_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComponentClassifierTraining\n",
    "### If model has been trained before:\n",
    "#### Then the train and save functions should be replaced with:\n",
    "training_obj.model.load_weights(PATH+name+'.h5')\n",
    "\n",
    "#### The \n",
    "training_obj = ComponentClassifierTraining(PATH, data_set_name, num_classes, dropout, TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL)\n",
    "training_obj.shuffle_data(training_obj.load_data(PATH,data_set_name),1000)\n",
    "training_obj.model = training_obj.load_sketch_a_net_model(dropout, num_classes, training_obj.X_train.shape[1:])\n",
    "\n",
    "training_obj.train(100)\n",
    "training_obj.save(name+'_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_obj = ComponentClassifierTraining(PATH, data_set_name, num_classes, dropout, TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL)\n",
    "training_obj.shuffle_data(training_obj.load_data(PATH,data_set_name),1000)\n",
    "training_obj.model = training_obj.load_sketch_a_net_model(dropout, num_classes, training_obj.X_train.shape[1:])\n",
    "\n",
    "training_obj.train(100)\n",
    "training_obj.save(name+'_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#training_obj.model.load_weights(PATH+name+'.h5')\n",
    "#\n",
    "#\n",
    "#trained_model = training_obj.model\n",
    "#\n",
    "################ ComponentClassifierPredict ################\n",
    "#prediction_obj = ComponentClassifierPredict(min_percent_match, min_confidence)\n",
    "#\n",
    "#ext_class_index, ext_class_name, \\\n",
    "#ext_match_first_max_percent, \\\n",
    "#ext_match_second_max_percent = prediction_obj.predict_classes(ext_images,trained_model)\n",
    "##'''\n",
    "#labelling_obj = ExtractionLabelling(PATH,\n",
    "#                          ext_images, ext_data,ext_class_index, ext_class_name, \n",
    "#                          num_classes, img_rows, img_cols)\n",
    "#\n",
    "##labelling_obj.define_model(trained_model)\n",
    "##labelling_obj.select_good_bounding_boxes(image, \"all_\" + str(image_index))\n",
    "#labelling_obj.plot_ground_truths(image, \"all_\" + str(image_index))\n",
    "\n",
    "#%% \n",
    "'''\n",
    "Test different sample sizes using Testing Class by loading data\n",
    "'''\n",
    "PATH = '/home/chloong/Desktop/Justin San Juan/Testing Folder/'\n",
    "\n",
    "# image_set = np.load(PATH+'all_training_images.npy')\n",
    "name = 'Sketch-a-Net_64_classes_100x100_0.0_all_100epochs'\n",
    "  \n",
    "data_set_name = 'Training_Samples_64_classes_100x100_all'\n",
    "start = 20000 # smallest sample size to be tested\n",
    "end =20000 # largest sample size to be tested\n",
    "step = 1000 # steps in sample sizes\n",
    "list_of_n = list(np.arange(start,end+1,step)) # list of sample sizes\n",
    "k = 10 # number of times the samples size is tested\n",
    "#list of_images = list(np.arange(0,200+1,5)) # list of images to be tested on\n",
    "iters = 200 # number of iterations in testing, also used for file naming\n",
    "testing_obj = TestingClass(PATH, wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "\n",
    "\n",
    "for n in list_of_n:\n",
    "    for i in range(k):\n",
    "        img_start = (i+6)*25\n",
    "        img_end = img_start+150\n",
    "        img_step = 5\n",
    "        list_images = list(np.arange(img_start,img_end,img_step))\n",
    "        \n",
    "        testing_obj = TestingClass(PATH, wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "        gc.collect()\n",
    "        seed = 1038+n+i*100\n",
    "        testing_obj.test_classifier_remapped_load_3_models(PATH+data_set_name, \n",
    "                                    TRAINING_RATIO_TRAIN, i, \n",
    "                                    n, iters, list_images, seed)\n",
    "        testing_obj=None\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "#%%\n",
    "#'''\n",
    "#Train 10 different models using different seeds\n",
    "#'''\n",
    "#\n",
    "#PATH = '/home/chloong/Desktop/Justin San Juan/Testing Folder/'\n",
    "#\n",
    "## image_set = np.load(PATH+'all_training_images.npy')\n",
    "#name = 'Sketch-a-Net_64_classes_100x100_0.0_all_100epochs'\n",
    "#seed = 4581\n",
    "#accuracies =[]\n",
    "#for i in range(1):\n",
    "#    print('BUILDING... '+str(i))\n",
    "#    seed = int(random.random()*10000)\n",
    "#    random.seed(seed)\n",
    "#    data_set_name = 'Training_Samples_64_classes_100x100_all'\n",
    "#    dropout = 0\n",
    "#    training_obj = ComponentClassifierTraining(PATH, data_set_name, num_classes, dropout, TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL)\n",
    "#    training_obj.shuffle_data(training_obj.load_data(PATH,data_set_name),seed)\n",
    "#    training_obj.model = training_obj.load_sketch_a_net_model(dropout, num_classes, training_obj.X_train.shape[1:])\n",
    "#    \n",
    "#    seed = int(random.random()*10000)\n",
    "#    random.seed(seed)\n",
    "#    \n",
    "#    training_obj.model.load_weights(name+'_'+str(i))\n",
    "#    training_obj.is_trained = True\n",
    "#    training_obj.get_stats()\n",
    "#    \n",
    "\n",
    "#%%\n",
    "'''\n",
    "Load different models\n",
    "'''\n",
    "\n",
    "PATH = '/home/chloong/Desktop/Justin San Juan/Testing Folder/'\n",
    "\n",
    "# image_set = np.load(PATH+'all_training_images.npy')\n",
    "name = 'Sketch-a-Net_64_classes_100x100_0.0_all_100epochs'\n",
    "seed = 4581\n",
    "for i in range(30):\n",
    "    print('BUILDING... '+str(i))\n",
    "    seed = int(random.random()*10000)\n",
    "    random.seed(seed)\n",
    "    data_set_name = 'Training_Samples_64_classes_100x100_all'\n",
    "    dropout = 0\n",
    "    training_obj = ComponentClassifierTraining(PATH, data_set_name, num_classes, dropout, TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL)\n",
    "    training_obj.shuffle_data(training_obj.load_data(PATH,data_set_name),seed)\n",
    "    training_obj.model = training_obj.load_sketch_a_net_model(dropout, num_classes, training_obj.X_train.shape[1:])\n",
    "    \n",
    "    seed = int(random.random()*10000)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    training_obj.train(200,seed)\n",
    "    training_obj.model.load_weights(name+'_'+str(i)+'.h5')\n",
    "    training_obj.\n",
    "#%%\n",
    "'''\n",
    "Test rotations\n",
    "'''\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to the image file\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the image from disk\n",
    "image = cv2.imread(args[\"image\"])\n",
    " \n",
    "# loop over the rotation angles\n",
    "for angle in np.arange(0, 360, 15):\n",
    "\trotated = imutils.rotate(image, angle)\n",
    "\tcv2.imshow(\"Rotated (Problematic)\", rotated)\n",
    "\tcv2.waitKey(0)\n",
    " \n",
    "# loop over the rotation angles again, this time ensuring\n",
    "# no part of the image is cut off\n",
    "for angle in np.arange(0, 360, 15):\n",
    "\trotated = imutils.rotate_bound(image, angle)\n",
    "\tcv2.imshow(\"Rotated (Correct)\", rotated)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "image = np.asarray(  \n",
    "        [[0,0,0,1,0,0,0,0,0,0],\n",
    "         [0,0,1,1,0,0,0,1,1,0],\n",
    "         [0,0,0,1,0,0,1,0,0,1],\n",
    "         [0,0,0,1,0,0,0,1,1,1],\n",
    "         [0,0,0,1,0,0,0,0,0,1],\n",
    "         [0,0,0,1,0,0,0,0,0,1],\n",
    "         [0,0,0,0,0,1,0,1,0,1],\n",
    "         [0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0]])\n",
    "\n",
    "    \n",
    "#%%\n",
    "PATH = '/home/chloong/Desktop/Justin San Juan/Testing Folder/'\n",
    "src_im = Image.open(PATH + \"sample01.JPG\")\n",
    "angle = 5\n",
    "size = 1000, 1000\n",
    "\n",
    "\n",
    "im = src_im\n",
    "rot = im.rotate(angle, expand=1 )\n",
    "rot.save(PATH + \"test.png\")\n",
    "\n",
    "#%%\n",
    "\n",
    "image = np.asarray(  \n",
    "        [[0,0,0,1,0,0,0,0,0,0],\n",
    "         [0,0,1,1,0,0,0,1,1,0],\n",
    "         [0,0,0,1,0,0,1,0,0,1],\n",
    "         [0,0,0,1,0,0,0,1,1,1],\n",
    "         [0,0,0,1,0,0,0,0,0,1],\n",
    "         [0,0,0,1,0,0,0,0,0,1],\n",
    "         [0,0,0,0,0,1,0,1,0,1],\n",
    "         [0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0]])\n",
    "data = [(1,0,4,7),(5,0,5,8)]\n",
    "\n",
    "extraction_obj = ExtractionPreprocessing(image, '', data)\n",
    "gt_extraction_list, gt_extraction_data = extraction_obj.preprocess_extractions(wanted_w, wanted_h, export_w, export_h,\n",
    "                                                max_piece_percent)\n",
    "b = np.asarray(\n",
    "        [[0,1],\n",
    "         [1,1],\n",
    "         [0,1],\n",
    "         [0,1],\n",
    "         [0,1],\n",
    "         [0,1]])\n",
    "c = np.asarray(\n",
    "        [[0,0,0,0,0],\n",
    "         [0,0,1,1,0],\n",
    "         [0,1,0,0,1],\n",
    "         [0,0,1,1,1],\n",
    "         [0,0,0,0,1],\n",
    "         [0,0,0,0,1],\n",
    "         [0,0,1,0,1],\n",
    "         [0,0,0,0,0]])\n",
    " #%%\n",
    "    # Create/reset list of images, coordinates (x,y,w,h) data, class indices, class names, and top three percentage matches\n",
    "ext_images=[]\n",
    "ext_data=[]\n",
    "ext_class_index=[]\n",
    "ext_class_name=[]\n",
    "ext_match_percent=[]\n",
    "ext_match_percent2=[]\n",
    "ext_next_round=[]\n",
    "ext_next_round_index=[]\n",
    "\n",
    "    # define wanted_w, and wanted_h, which is the are where the extraction is limited to\n",
    "    # define export_w and export_h as required by the classifier\n",
    "wanted_w=img_cols\n",
    "wanted_h=img_rows\n",
    "export_w=img_cols\n",
    "export_h=img_rows\n",
    "\n",
    "    # prepare extractions to be sent to classifier\n",
    "    # ext_class_index and _name are empty\n",
    "\n",
    "name = 'Sketch-a-Net_Single_Model_'+str(t)\n",
    "\n",
    "##############\n",
    "end = time.time()\n",
    "print('Segmentation done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "t2=end-start\n",
    "start = time.time()\n",
    "##############\n",
    "name = 'TestGaussian'+'_'+str(num_classes)+'_classes_'+str(img_rows)+'x'+str(img_cols)+'_'+str(a)#+'_gaussian'\n",
    "\n",
    "    # plot bounding boxes on original image\n",
    "plot_bounding_boxes_with_names(image,candidates, name) \n",
    "\n",
    "##############\n",
    "end = time.time()\n",
    "print('Plotting bounding boxes done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "t3=end-start\n",
    "start = time.time()\n",
    "##############\n",
    "    #load data only if not yet loaded, or update data if number of samples in data_all does not match current y_train number of data samples\n",
    "try: y_train\n",
    "except: \n",
    "    try:\n",
    "        data_all=np.load('Training_Samples_'+str(num_classes)+'_classes_'+str(img_rows)+'x'+str(img_cols)+'_all.npy')\n",
    "        if y_train.shape[0]==data_all.shape[0]:\n",
    "            y_train=y_train\n",
    "        else:\n",
    "            x_train, y_train, x_test, y_test,input_shape,data_all=load_data()\n",
    "    except:\n",
    "        x_train, y_train, x_test, y_test,input_shape,data_all=load_data()\n",
    "#data_all=np.load('Training_Samples_'+str(num_classes)+'_classes_'+str(img_rows)+'x'+str(img_cols)+'_all.npy')\n",
    "#x_train, y_train, x_test, y_test,input_shape,data_all=load_data()\n",
    "\n",
    "##############\n",
    "end = time.time()\n",
    "print('Loading training data done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "t4=end-start\n",
    "start = time.time()\n",
    "##############\n",
    "\n",
    "epochs=100\n",
    "group='all'\n",
    "    #list of dropout values to be tested\n",
    "#di=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "di=[0.0]\n",
    "for d in di:\n",
    "\n",
    "    name = 'Sketch-a-Net'+'_'+str(num_classes)+'_classes_'+str(img_rows)+'x'+str(img_cols)+'_'+str(d)#+'_gaussian'\n",
    "    print('name = '+name)\n",
    "    model = Sequential() #model needs to be defined as a global variable before using load_model_layers, train_model, or load_model_weights\n",
    "    \n",
    "    load_model_layers(d)\n",
    "#    train_model(epochs)\n",
    "#    save_model_weights(name,epochs)\n",
    "    print('loading model weights...')\n",
    "    load_model_weights(name,epochs)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1]) \n",
    "    name = 'TestGaussian'+'_'+str(num_classes)+'_classes_'+str(img_rows)+'x'+str(img_cols)+'_'+str(d)+'_'+str(a)#+'_gaussian'\n",
    "\n",
    "    ##############\n",
    "    end = time.time()\n",
    "    print('Loading/training model done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "    t5 = end-start\n",
    "    start = time.time()\n",
    "    ##############\n",
    "    \n",
    "    print('predicting classes...')\n",
    "    predict_classes(ext_images,group,ext_class_index,ext_class_name,ext_next_round,ext_next_round_index)\n",
    "    \n",
    "    ##############\n",
    "    end = time.time()\n",
    "    print('predict classes done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "    t6 = end-start\n",
    "    start = time.time()\n",
    "    ##############\n",
    "    \n",
    "   \n",
    "        #create figure with all extractions and percent matches if no answers\n",
    "    \n",
    "    select_good_bounding_boxes(image,imagename,ext_images,ext_data,ext_class_index,ext_class_name,target_names)\n",
    "    \n",
    "    print('plotting extractions with names...')\n",
    "#    plot_extractions_with_names(ext_images, ext_data, ext_class_name, ext_class_index, name) \n",
    "#    plot_extractions_with_names(ext_images, ext_data, ext_class_name, ext_class_index, name, ans = adjusted_ans) \n",
    "\n",
    "    ##############\n",
    "    end = time.time()\n",
    "    print('plot extractions with names done... Time Elapsed : '+str(end-start)+' seconds...')\n",
    "    t7 = end-start\n",
    "    start = time.time()\n",
    "    ##############\n",
    "    #update answers if necessary\n",
    "#update_answers(ext_images,ans) \n",
    "\n",
    "print('Loading image : ' + str(t1) + '\\n'\n",
    "      'Segmentation : ' + str(t2) + '\\n'\n",
    "      'Plot bounding boxes : ' + str(t3) + '\\n'\n",
    "      'Load training data : ' + str(t4) + '\\n'\n",
    "      'Load/train model : ' + str(t5) + '\\n'\n",
    "      'Predict classes : ' + str(t6) + '\\n'\n",
    "      'Plot extractions with names : ' + str(t7) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
