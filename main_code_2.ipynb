{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Based Structural Analysis\n",
    "### Code created and maintained by Justin David Q. SAN JUAN, <br>email: jdqsj1997@yahoo.com, <br> personal website: justinsj.weebly.com\n",
    "\n",
    "#### This code focuses in the segmentation and classification processes (except reconstruction) of the complete project pipeline as described below:\n",
    "<img src=\"https://justinsj.weebly.com/uploads/6/4/9/2/64923303/process-flowchart_orig.jpg\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "#### Dependencies:\n",
    "numpy: for handling data types (mostly handled as numpy arrays)<br>\n",
    "Sequential (from keras.models): for CNN setup<br>\n",
    "random: for pseudo-random shuffling of data<br>\n",
    "cv2: for raw RBG image import and transformation to grayscale<br>\n",
    "time: for measuring time elapsed per function<br>\n",
    "##### Custom Classes:\n",
    "ComponentSegmentation: for proposing regions of interest (RoI's)<br>\n",
    "ExtractionPreprocessing: for trimming, noise removal, and resizing of image<br>\n",
    "ComponentClassifierTraining: for loading the CNN model, training data, and training the model<br>\n",
    "ComponentClassifierPredict: for using the CNN model to predict the class of preprocessed extractions<br>\n",
    "ExtractionLabelling: for labelling ground truth bounding boxes and classes in problem images<br>\n",
    "TestingClass: for testing the accuracy of a CNN model on the problem images<br>\n",
    "<br>\n",
    "print_image_bw is used to print a simple 2-D array<br>\n",
    "gc: for clearing up space after acquiring data from larger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Importing...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from component_segmentation import ComponentSegmentation\n",
    "from extraction_preprocessing import ExtractionPreprocessing\n",
    "from component_classifier_training import ComponentClassifierTraining\n",
    "from component_classifier_predict import ComponentClassifierPredict\n",
    "from extraction_labelling import ExtractionLabelling\n",
    "from testing_class import TestingClass\n",
    "from helper_functions import print_image_bw\n",
    "from helper_functions import plot_model_results_and_save\n",
    "from helper_functions import print_time_string, store_time\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "print('Done Importing...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters\n",
    "#### Selective Search Parameters:\n",
    "scale_input<br>\n",
    "sigma_input<br>\n",
    "min_size_input<br>\n",
    "#### Noise Reduction Parameters:\n",
    "min_shape: for minimum number of black pixels in bounding box<br>\n",
    "min_height: for minimum height of bounding box<br>\n",
    "min_width: for minimum width of bounding box<br>\n",
    "<br>\n",
    "buffer_zone: for expanding bounding box all directions<br>\n",
    "min_area: for minimum area of bounding box<br>\n",
    "min_black: for minimum number of black pixels in bounding box<br>\n",
    "min_black_ratio: for minimum ratio of black pixels to the bounding box area<br>\n",
    "#### Overlap Parameters:\n",
    "overlap_repeats: for number of iterations for merging algorithm to be applied<br>\n",
    "overlap_threshold: threshold of area overlap over union area for merging to be applied<br>\n",
    "#### Removing Unconnected Pieces Parameters:\n",
    "max_piece_percent: maximum percentage of piece to be removed<br>\n",
    "(if percentage is larger, piece will not be removed as it is more likely an important piece)<br>\n",
    "#### Extractions Preprocessing Parameters:\n",
    "img_rows, img_cols: for classifier input shape<br>\n",
    "wanted_w, wanted_h: for black pixels edges resizing boundary shape<br>\n",
    "export_w, export_h: for overall image resizing shape ([export_w-wanted_w]/2 = horizontal buffer on each side)<br>\n",
    "#### CNN Training Parameters:\n",
    "num_classes: number of classes for classifier to predict<br>\n",
    "TRAINING_RATIO_TRAIN: ratio of training samples to total number of samples<br>\n",
    "TRAINING_RATIO_VAL: ratio of validation samples to total number of samples<br>\n",
    "TRAINING_RATIO_TEST: ratio of test samples to total number of samples <br>\n",
    "Note: TRAINING_RATIO_TEST is implicitly calculated as [1-{TRAINING_RATIO_TRAIN + TRAINING_RATIO_VAL}]<br>\n",
    "dropout: dropout value to be used in all layers except last layer of Sketch-A-Net CNN model<br>\n",
    "#### CNN Prediction Parameters:\n",
    "min_percent_match: minimum probability of class prediction for that class to be set as the prediction<br>\n",
    "min_confidence: minimum difference between first-highest % match and second-highest % match<br>\n",
    "(higher difference means less ambiguity between first and second highest match, which means less likelihood of random object)<br>\n",
    "##### The directory is also defined in the PATH variable.<br>The name of the CNN model data is defined in the name variable.<br>The training data set name for the CNN is defined in the data_set_name variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done setting hyperparamters...\n"
     ]
    }
   ],
   "source": [
    "#selective search parameters\n",
    "scale_input=200 #200 previous: #10\n",
    "sigma_input=10 #10 previous: #15\n",
    "min_size_input=10 #10 previous: #5\n",
    "\n",
    "#noise reduction parameters\n",
    "min_shape=10 #min. number of black pixels  \n",
    "min_height=3 #min. height of bounding box\n",
    "min_width=3 #min. width of bounding box\n",
    "\n",
    "buffer_zone=2 #expand bounding box by this amount in all directions  \n",
    "min_area=100 #min. area of bounding box\n",
    "min_black=10 #min. number of black pixels\n",
    "min_black_ratio=0.01 #min ratio of black pixels to the bounding box area\n",
    "\n",
    "#Overlap parameters\n",
    "overlap_repeats = 4 #set to 8\n",
    "overlap_threshold = 0.3 #set to 0.3 (overlap has to be larger than the threshold)\n",
    "\n",
    "#Removing unconnected pieces parameters\n",
    "max_piece_percent=0.3  # set to 0.3\n",
    "\n",
    "#Extractions preprocessing paramaters\n",
    "img_rows, img_cols = 100,100\n",
    "wanted_w, wanted_h, export_w, export_h = img_cols, img_rows, img_cols, img_rows\n",
    "\n",
    "#CNN training parameters\n",
    "num_classes = 64\n",
    "TRAINING_RATIO_TRAIN = 0.7\n",
    "TRAINING_RATIO_VAL = 0.15\n",
    "dropout = 0\n",
    "\n",
    "#CNN prediction parameters\n",
    "min_percent_match = 0 # set to 0.7\n",
    "min_confidence = 0 # set to 0.3\n",
    "\n",
    "#Time Cost parameters\n",
    "time_cost_string_list = ['Loading image','Component Segmentation','Extraction Preprocessing',\n",
    "                         'Component Classifier Training','Component Classifier Predict',\n",
    "                        'Printing Results','Acquiring and Printing Ground Truth Data',\n",
    "                        'Data Concatenation & Cleaning','Data Control, Counting, & Training from Multiple Files',\n",
    "                        'Testing','Printing Confusion Matrix']\n",
    "time_cost_time_list = np.zeros(len(time_cost_string_list)).astype(np.int).tolist()\n",
    "\n",
    "#Paths and names\n",
    "PATH = 'C:/Users/JustinSanJuan/Desktop/Workspace/python/Testing Folder/' #must have \"/\" at the end\n",
    "\n",
    "name = 'Sketch-a-Net_64_classes_100x100_0.0_all_100epochs'\n",
    "\n",
    "base_dataset_name = 'Training_Samples_64_classes_100x100_all'\n",
    "\n",
    "dataset_PATH = 'C:/Users/JustinSanJuan/Desktop/HKUST/UROP Deep Learning Image-based Structural Analysis/Code/Python/Testing Folder/'\n",
    "dataset_name = 'Training_Samples_64_classes_100x100_all_cleaned_32898'\n",
    "new_dataset_name = 'Training_Samples_64_classes_100x100_all_cleaned_32898'\n",
    "\n",
    "print('Done setting hyperparamters...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset_2 first controlled to 600 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        14464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 512)         262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "=================================================================\n",
      "Total params: 5,267,520.0\n",
      "Trainable params: 5,267,520.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "testing on image number: 350\n",
      "testing on image number: 351\n",
      "testing on image number: 352\n",
      "testing on image number: 353\n",
      "testing on image number: 354\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-120598cb27f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m                                      \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                      \u001b[0mTRAINING_RATIO_TRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAINING_RATIO_VAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                                      200,seed,350,706, weights_name = weights_name)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#record time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Workspace\\python\\isa_python\\testing_class.py\u001b[0m in \u001b[0;36mtest_classifier_multiple_slow\u001b[1;34m(self, dataset_PATH, dataset_name_list, num_classes, dropout, TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL, iters, seed, start, end, weights_name)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0mprediction_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_from_gt_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_extraction_list_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                     \u001b[0mground_truth_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgt_indices_list_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Workspace\\python\\isa_python\\testing_class.py\u001b[0m in \u001b[0;36mpredict_from_gt_image\u001b[1;34m(self, ground_truth_image, trained_model_1, trained_model_2, trained_model_3)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;31m#            index, first_max, second_max = prediction_obj.predict_class(ground_truth_image,trained_model_1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_class_with_rotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mground_truth_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrained_model_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Workspace\\python\\isa_python\\component_classifier_predict.py\u001b[0m in \u001b[0;36mpredict_class_with_rotations\u001b[1;34m(self, image, model_1, model_2, model_3)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mrotated_image_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mextraction_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtractionPreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated_image_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mextraction_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated_image_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel_2\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel_3\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_class_3_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated_image_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Workspace\\python\\isa_python\\extraction_preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_extraction\u001b[1;34m(self, extraction, wanted_w, wanted_h, export_w, export_h, max_piece_percent, x, y, w, h)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#            plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mextraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mextraction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Workspace\\python\\isa_python\\extraction_preprocessing.py\u001b[0m in \u001b[0;36mresize_extraction\u001b[1;34m(self, extraction, x, y, w, h, wanted_w, wanted_h, export_w, export_h)\u001b[0m\n\u001b[0;32m     55\u001b[0m                     \u001b[0mh_down\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mduplication_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                     \u001b[0mextraction1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_up\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh_down\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_left\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw_right\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextraction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mextraction2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextraction1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time() # Begin time measurement\n",
    "\n",
    "seed = 1000\n",
    "\n",
    "weights_name = \"Sketch-A-Net_controlled_600_30858\"\n",
    "#weights_name = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739+7500(0-350)\"\n",
    "#weights_name = dataset_name\n",
    "#dataset_name_1 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739\"\n",
    "#dataset_name_2 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_7500_0-350\"\n",
    "dataset_name_list = [\"Training_Samples_64_classes_100x100_all_controlled_30858\"]\n",
    "\n",
    "### Long procedure\n",
    "testing_obj = TestingClass(dataset_PATH, wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "# Slower does testing with as little memory at all times as possible\n",
    "ground_truth_list, prediction_list = testing_obj.test_classifier_multiple_slow(dataset_PATH, dataset_name_list,\n",
    "                                     num_classes,dropout, \n",
    "                                     TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL,\n",
    "                                     200,seed,350,706, weights_name = weights_name)\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(9,time_cost_time_list,end-start)\n",
    "print_time_string(9,time_cost_string_list,time_cost_time_list)\n",
    "\n",
    "start = time.time() # Begin time measurement\n",
    "\n",
    "confusion_matrix_index = 1\n",
    "\n",
    "#Add base data for confusion matrix\n",
    "for i in range(64):\n",
    "    ground_truth_list.append(i)\n",
    "    prediction_list.append(i)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(ground_truth_list,prediction_list)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "from helper_functions import plot_confusion_matrix\n",
    "from constants import target_names_all\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names_all,\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix', \n",
    "                      cmap=plt.cm.Blues,PATH=dataset_PATH, name=\"confusion_matrix_\"+str(confusion_matrix_index), verbose = False)\n",
    "\n",
    "from helper_functions import confusion_matrix_analysis\n",
    "dataset_PATH = \"C:/Users/JustinSanJuan/Desktop/HKUST/UROP Deep Learning Image-based Structural Analysis/Code/Python/Testing Folder/\"\n",
    "name = \"confusion_matrix_\"+str(confusion_matrix_index)+\"_analysis\"\n",
    "min_count = 5\n",
    "confusion_matrix_analysis(cnf_matrix, dataset_PATH, name, min_count, verbose = False) #Turn verbose on to show data analysis\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(10,time_cost_time_list,end-start)\n",
    "print_time_string(10,time_cost_string_list,time_cost_time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset_2 first controlled to 600 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time() # Begin time measurement\n",
    "\n",
    "seed = 1000\n",
    "\n",
    "weights_name = \"Sketch-A-Net_controlled_600_30858_1\"\n",
    "#weights_name = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739+7500(0-350)\"\n",
    "#weights_name = dataset_name\n",
    "#dataset_name_1 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739\"\n",
    "#dataset_name_2 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_7500_0-350\"\n",
    "dataset_name_list = [\"Training_Samples_64_classes_100x100_all_controlled_30858_1\"]\n",
    "\n",
    "### Long procedure\n",
    "testing_obj = TestingClass(dataset_PATH, wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "# Slower does testing with as little memory at all times as possible\n",
    "ground_truth_list, prediction_list = testing_obj.test_classifier_multiple_slow(dataset_PATH, dataset_name_list,\n",
    "                                     num_classes,dropout, \n",
    "                                     TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL,\n",
    "                                     200,seed,350,706, weights_name = weights_name)\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(9,time_cost_time_list,end-start)\n",
    "print_time_string(9,time_cost_string_list,time_cost_time_list)\n",
    "\n",
    "start = time.time() # Begin time measurement\n",
    "\n",
    "confusion_matrix_index = 1\n",
    "\n",
    "#Add base data for confusion matrix\n",
    "for i in range(64):\n",
    "    ground_truth_list.append(i)\n",
    "    prediction_list.append(i)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(ground_truth_list,prediction_list)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "from helper_functions import plot_confusion_matrix\n",
    "from constants import target_names_all\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names_all,\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix', \n",
    "                      cmap=plt.cm.Blues,PATH=dataset_PATH, name=\"confusion_matrix_\"+str(confusion_matrix_index), verbose = False)\n",
    "\n",
    "from helper_functions import confusion_matrix_analysis\n",
    "dataset_PATH = \"C:/Users/JustinSanJuan/Desktop/HKUST/UROP Deep Learning Image-based Structural Analysis/Code/Python/Testing Folder/\"\n",
    "name = \"confusion_matrix_\"+str(confusion_matrix_index)+\"_analysis\"\n",
    "min_count = 5\n",
    "confusion_matrix_analysis(cnf_matrix, dataset_PATH, name, min_count, verbose = False) #Turn verbose on to show data analysis\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(10,time_cost_time_list,end-start)\n",
    "print_time_string(10,time_cost_string_list,time_cost_time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude 23's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time() # Begin time measurement\n",
    "\n",
    "seed = 1000\n",
    "\n",
    "weights_name = \"Sketch-A-Net_exclude_23_32898\"\n",
    "#weights_name = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739+7500(0-350)\"\n",
    "#weights_name = dataset_name\n",
    "#dataset_name_1 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_29739\"\n",
    "#dataset_name_2 = \"Training_Samples_64_classes_100x100_all_cleaned_updated_7500_0-350\"\n",
    "dataset_name_list = [\"Training_Samples_64_classes_100x100_all_cleaned_32898\"]\n",
    "\n",
    "### Long procedure\n",
    "testing_obj = TestingClass(dataset_PATH, wanted_w, wanted_h, export_w, export_h, max_piece_percent)\n",
    "# Slower does testing with as little memory at all times as possible\n",
    "ground_truth_list, prediction_list = testing_obj.test_classifier_multiple_slow(dataset_PATH, dataset_name_list,\n",
    "                                     num_classes,dropout, \n",
    "                                     TRAINING_RATIO_TRAIN, TRAINING_RATIO_VAL,\n",
    "                                     200,seed,350,706, weights_name = weights_name)\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(9,time_cost_time_list,end-start)\n",
    "print_time_string(9,time_cost_string_list,time_cost_time_list)\n",
    "\n",
    "start = time.time() # Begin time measurement\n",
    "\n",
    "confusion_matrix_index = 1\n",
    "\n",
    "#Add base data for confusion matrix\n",
    "for i in range(64):\n",
    "    ground_truth_list.append(i)\n",
    "    prediction_list.append(i)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(ground_truth_list,prediction_list)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "from helper_functions import plot_confusion_matrix\n",
    "from constants import target_names_all\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names_all,\n",
    "                      normalize=False,\n",
    "                      title='Confusion matrix', \n",
    "                      cmap=plt.cm.Blues,PATH=dataset_PATH, name=\"confusion_matrix_\"+str(confusion_matrix_index), verbose = False)\n",
    "\n",
    "from helper_functions import confusion_matrix_analysis\n",
    "dataset_PATH = \"C:/Users/JustinSanJuan/Desktop/HKUST/UROP Deep Learning Image-based Structural Analysis/Code/Python/Testing Folder/\"\n",
    "name = \"confusion_matrix_\"+str(confusion_matrix_index)+\"_analysis\"\n",
    "min_count = 5\n",
    "confusion_matrix_analysis(cnf_matrix, dataset_PATH, name, min_count, verbose = False) #Turn verbose on to show data analysis\n",
    "\n",
    "end = time.time()#record time\n",
    "time_cost_time_list = store_time(10,time_cost_time_list,end-start)\n",
    "print_time_string(10,time_cost_string_list,time_cost_time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Time Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "time_cost_string = ''\n",
    "for i in range(len(time_cost_string_list)):\n",
    "    time_cost_string += time_cost_string_list[i] +' : ' + time_cost_time_list[i]+'\\n'\n",
    "print(time_cost_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
